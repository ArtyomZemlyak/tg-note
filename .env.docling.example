# =====================================================
# Docling MCP Container Configuration
# =====================================================
# Copy this file to .env or merge with your existing .env file

# -----------------------------------------------------
# Docling Container Settings
# -----------------------------------------------------

# Logging level for Docling container
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
DOCLING_LOG_LEVEL=INFO

# Docling MCP server port (exposed to host)
DOCLING_MCP_PORT=8077

# -----------------------------------------------------
# GPU Configuration
# -----------------------------------------------------

# GPU device selection
# Options: all, 0, 1, 0,1 (comma-separated list)
DOCLING_CUDA_VISIBLE_DEVICES=all

# Number of GPUs to allocate
# Options: all, 1, 2, etc.
DOCLING_GPU_COUNT=all

# CUDA version for Docker image build
# Options: 11.8.0, 12.1.0, 12.2.0, etc.
CUDA_VERSION=12.1.0

# -----------------------------------------------------
# OCR Backend Configuration
# -----------------------------------------------------

# Default OCR backend to use
# Options: rapidocr, easyocr, tesseract, tesseract_cli, onnxtr, none
# Note: This can be overridden by config.yaml or Telegram settings
DOCLING_OCR_BACKEND=rapidocr

# -----------------------------------------------------
# Model Download Configuration
# -----------------------------------------------------

# HuggingFace token (optional, for private models)
# Get it from: https://huggingface.co/settings/tokens
# HF_TOKEN=your_huggingface_token_here

# ModelScope token (optional, for private models)
# MODELSCOPE_TOKEN=your_modelscope_token_here

# Enable fast model transfer via HuggingFace hub
# Options: 0, 1
HF_HUB_ENABLE_HF_TRANSFER=1

# -----------------------------------------------------
# Directory Paths (inside container)
# -----------------------------------------------------
# These are internal container paths and should not be changed
# unless you know what you're doing

DOCLING_MODELS_DIR=/opt/docling-mcp/models
DOCLING_CACHE_DIR=/opt/docling-mcp/cache
DOCLING_LOG_DIR=/opt/docling-mcp/logs

# -----------------------------------------------------
# Advanced Settings
# -----------------------------------------------------

# Container configuration directory path
# Used by tg-note to write docling-config.json
DOCLING_CONTAINER_CONFIG_DIR=data/docling/config

# Docling MCP URL (auto-detected in Docker, can be overridden)
# For host machine: http://127.0.0.1:8077/sse
# For Docker network: http://docling-mcp:8077/sse
# DOCLING_MCP_URL=http://docling-mcp:8077/sse

# -----------------------------------------------------
# Example Configurations
# -----------------------------------------------------

# === RapidOCR (Default, Recommended) ===
# Fast, lightweight, good accuracy
# Best for: General documents, Chinese/English text
# DOCLING_OCR_BACKEND=rapidocr

# === EasyOCR ===
# Multilingual support (80+ languages)
# Best for: Multilingual documents, rare languages
# DOCLING_OCR_BACKEND=easyocr

# === Tesseract ===
# Mature, stable, offline
# Best for: Legacy documents, offline processing
# DOCLING_OCR_BACKEND=tesseract

# === OnnxTR ===
# Custom ONNX models
# Best for: Custom OCR pipelines
# DOCLING_OCR_BACKEND=onnxtr

# -----------------------------------------------------
# Resource Limits (Optional)
# -----------------------------------------------------

# Shared memory size for container (important for GPU operations)
# Default: 2gb (set in docker-compose.yml)
# DOCLING_SHM_SIZE=2gb

# Memory limit for container (optional)
# DOCLING_MEMORY_LIMIT=8g

# CPU limit for container (optional, cores)
# DOCLING_CPU_LIMIT=4

# -----------------------------------------------------
# Monitoring & Debugging
# -----------------------------------------------------

# Enable CUDA debug output
# CUDA_LAUNCH_BLOCKING=1

# Enable ONNX Runtime verbose logging
# ORT_LOGGING_LEVEL=2

# Enable PyTorch debug mode
# TORCH_DISTRIBUTED_DEBUG=DETAIL

# -----------------------------------------------------
# Notes
# -----------------------------------------------------

# 1. Configuration Priority:
#    Environment Variables > config.yaml > Telegram Settings > Defaults
#
# 2. Model Downloads:
#    - First startup may take 5-10 minutes
#    - Models are cached in data/docling/models/
#    - Progress shown in container logs
#
# 3. GPU Requirements:
#    - NVIDIA GPU with CUDA support
#    - nvidia-docker2 installed
#    - Drivers compatible with CUDA version
#
# 4. Changing Settings:
#    - Use Telegram /settings command (recommended)
#    - Or edit config.yaml and restart container
#    - Or set environment variables and restart
#
# 5. Troubleshooting:
#    - Check logs: docker-compose logs -f docling-mcp
#    - Verify GPU: docker exec tg-note-docling nvidia-smi
#    - Check models: ls -lah data/docling/models/
#    - View config: cat data/docling/config/docling-config.json
