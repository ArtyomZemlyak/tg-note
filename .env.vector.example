# ═══════════════════════════════════════════════════════════════════════════════
# Environment Variables for Docker Compose with Vector Search
# ═══════════════════════════════════════════════════════════════════════════════
# Copy this file to .env and fill in your values
# Usage: docker-compose -f docker-compose.vector.yml up -d

# ───────────────────────────────────────────────────────────────────────────────
# Telegram Bot Configuration (REQUIRED)
# ───────────────────────────────────────────────────────────────────────────────

# Your Telegram bot token from @BotFather
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Comma-separated list of allowed user IDs (leave empty to allow all users)
# Find your ID: message @userinfobot
ALLOWED_USER_IDS=123456789,987654321

# ───────────────────────────────────────────────────────────────────────────────
# Qdrant Configuration (Vector Database)
# ───────────────────────────────────────────────────────────────────────────────

# Qdrant HTTP API port
QDRANT_PORT=6333

# Qdrant gRPC API port (optional, for high-performance clients)
QDRANT_GRPC_PORT=6334

# Default collection name for knowledge base
# Each user's KB can have a separate collection
QDRANT_COLLECTION=knowledge_base

# Optional: Qdrant API key for authentication (production)
# VECTOR_QDRANT_API_KEY=your-secret-qdrant-api-key

# ───────────────────────────────────────────────────────────────────────────────
# Infinity Configuration (Embedding Service)
# ───────────────────────────────────────────────────────────────────────────────

# Infinity API port
INFINITY_PORT=7997

# Embedding model to use
# Recommended models:
# - BAAI/bge-small-en-v1.5 (English, fast, 384 dim) - Default
# - BAAI/bge-base-en-v1.5 (English, balanced, 768 dim)
# - BAAI/bge-large-en-v1.5 (English, best quality, 1024 dim)
# - BAAI/bge-m3 (Multilingual, 1024 dim) - Best for Russian + English
# - sentence-transformers/all-MiniLM-L6-v2 (Fast, compact, 384 dim)
INFINITY_MODEL=BAAI/bge-small-en-v1.5

# Batch size for embedding generation
# Higher = faster but more memory
# Lower = slower but less memory
# Recommended: 32 (default), 16 (limited RAM), 64 (powerful hardware)
INFINITY_BATCH_SIZE=32

# Optional: Infinity API key for authentication
# VECTOR_INFINITY_API_KEY=your-secret-infinity-api-key

# ───────────────────────────────────────────────────────────────────────────────
# MCP Hub Configuration
# ───────────────────────────────────────────────────────────────────────────────

# MCP Hub API port
MCP_PORT=8765

# ───────────────────────────────────────────────────────────────────────────────
# Optional: API Keys for AI Services
# ───────────────────────────────────────────────────────────────────────────────

# OpenAI API Key (for OpenAI models, optional)
# OPENAI_API_KEY=sk-...

# Anthropic API Key (for Claude models, optional)
# ANTHROPIC_API_KEY=sk-ant-...

# Qwen API Key (for Qwen models via API, optional)
# QWEN_API_KEY=your-qwen-api-key

# OpenAI Base URL (for custom OpenAI-compatible endpoints)
# OPENAI_BASE_URL=http://localhost:8000/v1

# ───────────────────────────────────────────────────────────────────────────────
# Optional: GitHub Integration
# ───────────────────────────────────────────────────────────────────────────────

# GitHub Personal Access Token (for GitHub integration)
# GITHUB_TOKEN=ghp_...

# GitHub Username (for HTTPS authentication)
# GITHUB_USERNAME=your-github-username

# ═══════════════════════════════════════════════════════════════════════════════
# NOTES
# ═══════════════════════════════════════════════════════════════════════════════
#
# 1. Vector Search Configuration:
#    - Vector search settings are in config.yaml, not .env
#    - Set VECTOR_SEARCH_ENABLED: true in config.yaml
#    - See config.example.yaml for all vector search options
#
# 2. Model Selection:
#    - For English only: BAAI/bge-small-en-v1.5
#    - For multilingual (Russian + English): BAAI/bge-m3
#    - For best quality: BAAI/bge-large-en-v1.5
#
# 3. Performance:
#    - GPU acceleration: Uncomment deploy section in docker-compose.vector.yml
#    - Increase INFINITY_BATCH_SIZE for faster processing (if you have RAM)
#    - Smaller models = faster, but slightly lower quality
#
# 4. Data Storage:
#    - Qdrant data: ./data/qdrant_storage/
#    - Infinity cache: ./data/infinity_cache/
#    - Vector index metadata: ./data/vector_index/
#
# 5. Security:
#    - For production: set VECTOR_QDRANT_API_KEY and VECTOR_INFINITY_API_KEY
#    - Limit ALLOWED_USER_IDS to trusted users only
#    - Never commit .env file to git
#
# ═══════════════════════════════════════════════════════════════════════════════
