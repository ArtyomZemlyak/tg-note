# ═══════════════════════════════════════════════════════════════════════════════
# Environment Variables (Credentials and URLs Only)
# ═══════════════════════════════════════════════════════════════════════════════
# IMPORTANT: This file contains ONLY sensitive credentials and external service URLs.
# All other configuration should be in config.yaml
#
# Copy this file to .env and fill in your actual values
# ═══════════════════════════════════════════════════════════════════════════════

# ───────────────────────────────────────────────────────────────────────────────
# Credentials (Required)
# ───────────────────────────────────────────────────────────────────────────────

# Telegram Bot Token (get from @BotFather)
TELEGRAM_BOT_TOKEN=your_bot_token_here

# ALLOWED_USER_IDS - Docker Mode Only
# IMPORTANT: Only uncomment and set this in docker mode if you want to restrict users.
# Leave commented out for local development (use config.yaml instead)
# If set to empty string in docker, it may cause errors.
# Format: comma-separated IDs like "123456789,987654321" or JSON array [123456789,987654321]
# ALLOWED_USER_IDS=

# API Keys (Optional - for AI agents)
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
QWEN_API_KEY=
ANTHROPIC_API_KEY=

# GitHub Credentials (Optional - for git push via HTTPS)
# If you use HTTPS remotes, set these to enable automatic authentication
# Get token from: https://github.com/settings/tokens
GITHUB_TOKEN=
GITHUB_USERNAME=

# GitLab Credentials (Optional - for git push via HTTPS)
# If you use HTTPS remotes with GitLab, set these to enable automatic authentication
# Get token from: https://gitlab.com/-/profile/personal_access_tokens
GITLAB_TOKEN=
GITLAB_USERNAME=

# HuggingFace Token (Optional - for private models)
# Get it from: https://huggingface.co/settings/tokens
HF_TOKEN=

# ModelScope Token (Optional - for private models)
MODELSCOPE_TOKEN=

# ───────────────────────────────────────────────────────────────────────────────
# Docker-Specific Settings (Only needed when using docker-compose)
# ───────────────────────────────────────────────────────────────────────────────
# These are ONLY for external services and docker networking.
# Application settings should be configured in config.yaml (which is mounted to containers)
# ───────────────────────────────────────────────────────────────────────────────

# vLLM/SGLang Service Settings (for docker-compose only)
# Port for vLLM/SGLang container
VLLM_PORT=8001

# MEM Agent Configuration (for docker-compose only)
# These environment variables override config.yaml settings for Docker mode
# MEM_AGENT_BASE_URL=http://vllm-server:8001/v1
# MEM_AGENT_OPENAI_API_KEY=lm-studio

# Docker Internal Networking (for docker-compose only)
MCP_HUB_URL=http://mcp-hub:8765/sse
MCP_PORT=8765
DOCLING_MCP_PORT=8077

# GPU Configuration (for docker-compose only)
# Number of GPUs to allocate for docling-mcp (all, 1, 2, etc.)
DOCLING_GPU_COUNT=all

# vLLM/SGLang Model Configuration (for docker-compose only)
# These can be overridden in .env if needed
# MEM_AGENT_MODEL=driaforall/mem-agent
# GPU_MEMORY_UTILIZATION=0.8
# MAX_MODEL_LEN=4096
# TENSOR_PARALLEL_SIZE=1

# Vector Search Services (Optional - uncomment if using vector search)
# QDRANT_PORT=6333
# QDRANT_GRPC_PORT=6334
# INFINITY_PORT=7997
