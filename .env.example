# ═══════════════════════════════════════════════════════════════════════════════
# Environment Variables (Credentials Only)
# ═══════════════════════════════════════════════════════════════════════════════
# IMPORTANT: This file contains ONLY sensitive credentials and external service settings.
# All other configuration should be in config.yaml
#
# Copy this file to .env and fill in your actual values
# ═══════════════════════════════════════════════════════════════════════════════

# ───────────────────────────────────────────────────────────────────────────────
# Credentials (Required)
# ───────────────────────────────────────────────────────────────────────────────

# Telegram Bot Token (get from @BotFather)
TELEGRAM_BOT_TOKEN=your_bot_token_here

# ALLOWED_USER_IDS - Docker Mode Only
# IMPORTANT: Only uncomment and set this in docker mode if you want to restrict users.
# Leave commented out for local development (use config.yaml instead)
# If set to empty string in docker, it may cause errors.
# Format: comma-separated IDs like "123456789,987654321" or JSON array [123456789,987654321]
# ALLOWED_USER_IDS=

# API Keys (Optional - for AI agents)
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1
QWEN_API_KEY=
ANTHROPIC_API_KEY=

# GitHub Credentials (Optional - for git push via HTTPS)
# If you use HTTPS remotes, set these to enable automatic authentication
# Get token from: https://github.com/settings/tokens
GITHUB_TOKEN=
GITHUB_USERNAME=

# GitLab Credentials (Optional - for git push via HTTPS)
# If you use HTTPS remotes with GitLab, set these to enable automatic authentication
# Get token from: https://gitlab.com/-/profile/personal_access_tokens
GITLAB_TOKEN=
GITLAB_USERNAME=


# ───────────────────────────────────────────────────────────────────────────────
# Docker-Specific Settings (Only needed when using docker-compose)
# ───────────────────────────────────────────────────────────────────────────────
# These are ONLY for external services (vLLM) and docker networking.
# Application settings should be configured in config.yaml (which is mounted to containers)
# ───────────────────────────────────────────────────────────────────────────────

# vLLM Service Settings (external service configuration - for docker-compose only)
# Port for vLLM container
VLLM_PORT=8001
GPU_MEMORY_UTILIZATION=0.8
MAX_MODEL_LEN=4096
TENSOR_PARALLEL_SIZE=1
HF_HOME=/root/.cache/huggingface

# MEM Agent Configuration (Optional - prefer config.yaml for non-Docker setup)
# These environment variables override config.yaml settings
# For local development, configure in config.yaml instead
# For Docker, you can set these here:
# MEM_AGENT_BASE_URL=http://host.docker.internal:8001/v1
# MEM_AGENT_OPENAI_API_KEY=lm-studio

# Docker Internal Networking (for docker-compose only)
MCP_HUB_URL=http://mcp-hub:8765/sse
MCP_PORT=8765
