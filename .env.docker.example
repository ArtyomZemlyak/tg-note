# Docker Environment Configuration
# Copy this file to .env and fill in your credentials
# 
# NOTE: This file contains ONLY credentials and secrets.
# All other configuration is in config.yaml

# ============================================================================
# CREDENTIALS - Telegram Bot
# ============================================================================
TELEGRAM_BOT_TOKEN=your-telegram-bot-token-here
# Comma-separated list of allowed user IDs (empty = allow all users)
ALLOWED_USER_IDS=

# ============================================================================
# CREDENTIALS - LLM API Keys (Optional - depends on agent type in config.yaml)
# ============================================================================
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
QWEN_API_KEY=
OPENAI_BASE_URL=
GITHUB_TOKEN=

# ============================================================================
# INFERENCE SERVER - vLLM/SGLang Configuration
# (Only for mem-agent storage mode)
# ============================================================================
# Model to load (HuggingFace model ID)
MEM_AGENT_MODEL=driaforall/mem-agent

# GPU settings
GPU_MEMORY_UTILIZATION=0.8
MAX_MODEL_LEN=4096
TENSOR_PARALLEL_SIZE=1

# Port (internal to Docker)
VLLM_PORT=8001
MCP_PORT=8765

# ============================================================================
# NOTE: All other settings are in config.yaml
# ============================================================================
# See config.yaml for:
# - Agent type and model
# - MCP settings
# - Memory storage configuration
# - Knowledge base settings
# - Logging level
# etc.
