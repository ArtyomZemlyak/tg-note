# Docker Deployment - Summary

This document summarizes the Docker deployment setup for tg-note.

## ğŸ“ Created Files

### Core Deployment Files

1. **docker-compose.yml** - Main orchestration file
   - Defines all three services (bot, mcp-http-server, vllm-server)
   - Configures networks and volumes
   - Full GPU-enabled setup

2. **docker-compose.simple.yml** - Simplified version
   - Only bot + MCP server
   - JSON storage mode
   - No GPU required
   - Perfect for testing

3. **docker-compose.override.yml.example** - Customization template
   - Examples for common customizations
   - Override main configuration without modifying it

### Dockerfiles

4. **Dockerfile.bot** - Bot service
   - Multi-stage build
   - Python 3.11 slim base
   - Includes git for KB operations

5. **Dockerfile.mcp** - MCP HTTP server
   - Multi-stage build
   - Includes FastMCP and mem-agent dependencies
   - No GPU-specific packages

6. **Dockerfile.vllm** - vLLM inference server
   - Based on official vLLM image
   - GPU-enabled
   - OpenAI-compatible API

### Configuration Files

7. **.dockerignore** - Build context optimization
   - Excludes unnecessary files from images
   - Reduces build time and image size

8. **.env.docker.example** - Environment template
   - All available configuration options
   - Comments explaining each variable
   - Default values

### Documentation

9. **README.Docker.md** - Comprehensive guide
   - Architecture overview
   - Deployment instructions
   - Troubleshooting
   - Performance tuning

10. **QUICKSTART.Docker.md** - Quick start guide
    - Get running in 5 minutes
    - Step-by-step instructions
    - Common commands

11. **DOCKER_ARCHITECTURE.md** - Technical documentation
    - System architecture
    - Service communication
    - Data flow
    - Resource requirements
    - Scaling considerations

### Automation

12. **Makefile** - Command shortcuts
    - `make setup` - Initial setup
    - `make up` - Start services
    - `make logs` - View logs
    - `make json/vector/mem-agent` - Switch storage modes

13. **.github/workflows/docker-build.yml.example** - CI/CD template
    - Automated image builds
    - Multi-platform support
    - Security scanning

### Updates to Existing Files

14. **.gitignore** - Updated
    - Added Docker-related entries
    - Ignore override files and backups

15. **src/agents/mcp/memory/memory_server_http.py** - Enhanced
    - Added `/health` endpoint for Docker health checks

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Telegram Bot   â”‚  Port: -
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Port: 8765
â”‚ MCP HTTP Server â”‚
â”‚   (Gateway)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Storage â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  json   â”‚ â† Simple, fast (default)
   â”‚ vector  â”‚ â† Semantic search
   â”‚mem-agentâ”‚ â† AI-powered (needs vLLM)
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚ (if mem-agent)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Port: 8001
â”‚  vLLM Server    â”‚  GPU: Required
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Minimal Setup (No GPU)

```bash
# 1. Setup
make setup

# 2. Configure (edit .env)
nano .env

# 3. Start
make up-simple

# 4. Check
make logs
```

### Full Setup (With GPU)

```bash
# 1. Setup
make setup

# 2. Configure (edit .env)
nano .env

# 3. Start all services
make up

# 4. Check status
make ps
make logs
```

## ğŸ“Š Storage Modes

| Mode | Command | GPU | Speed | Features |
|------|---------|-----|-------|----------|
| JSON | `make json` | No | âš¡ Fast | Simple storage |
| Vector | `make vector` | No | ğŸ” Medium | Semantic search |
| Mem-Agent | `make mem-agent` | Yes | ğŸ¤– Slower | AI-powered |

## ğŸ”§ Common Commands

```bash
# Setup & Build
make setup              # Initial setup
make build             # Build images

# Start/Stop
make up                # Start all (with GPU)
make up-simple         # Start without GPU
make down              # Stop all
make restart           # Restart all

# Monitoring
make logs              # All logs
make logs-bot          # Bot logs
make logs-mcp          # MCP logs
make ps                # Status
make health            # Health check

# Maintenance
make rebuild           # Rebuild & restart
make backup            # Backup data
make clean             # Remove all (deletes data!)

# Storage modes
make json              # JSON mode
make vector            # Vector mode
make mem-agent         # Mem-agent mode
```

## ğŸ“ Configuration

### Environment Variables (.env)

**Required:**
```bash
TELEGRAM_BOT_TOKEN=your-token
```

**Optional but recommended:**
```bash
# Agent
AGENT_TYPE=qwen_code
QWEN_API_KEY=your-key

# Memory
AGENT_ENABLE_MCP_MEMORY=true
MEM_AGENT_STORAGE_TYPE=json|vector|mem-agent

# For mem-agent mode
MEM_AGENT_MODEL=driaforall/mem-agent
MEM_AGENT_BACKEND=vllm
```

## ğŸ’¾ Data Persistence

All data is stored in local directories:

```
./data/memory/        # Per-user memory
./knowledge_base/     # Git-based KB
./logs/              # Application logs
```

Shared model cache in Docker volume:
```
huggingface-cache    # HuggingFace models
```

## ğŸ”’ Security

1. **Never commit `.env` file**
2. Use `ALLOWED_USER_IDS` to restrict access
3. Keep ports internal (default)
4. Regular updates

```bash
chmod 600 .env
chmod 700 data/
```

## ğŸ› Troubleshooting

### Bot not starting
```bash
make logs-bot
# Check: TELEGRAM_BOT_TOKEN set?
```

### MCP server issues
```bash
make logs-mcp
curl http://localhost:8765/health
```

### vLLM GPU errors
```bash
nvidia-smi
make logs-vllm
# Reduce GPU_MEMORY_UTILIZATION in .env
```

## ğŸ“š Documentation

- **Quick Start:** [QUICKSTART.Docker.md](QUICKSTART.Docker.md)
- **Full Guide:** [README.Docker.md](README.Docker.md)
- **Architecture:** [DOCKER_ARCHITECTURE.md](DOCKER_ARCHITECTURE.md)

## ğŸ¯ What's Next?

1. âœ… Setup completed
2. ğŸ“± Message your bot on Telegram
3. ğŸ’¾ Bot stores memories automatically
4. ğŸ” Use `/memory` to search
5. ğŸ“š Integrate with knowledge base

## âœ¨ Features

- ğŸ³ **Easy deployment** - One command to start
- ğŸ”„ **Multiple storage modes** - JSON, Vector, AI-powered
- ğŸ“¦ **Self-contained** - All dependencies included
- ğŸ”§ **Configurable** - Environment-based config
- ğŸ“Š **Health checks** - Automatic monitoring
- ğŸ’¾ **Persistent data** - Volume-based storage
- ğŸš€ **Production-ready** - Resource limits, restarts

## ğŸ¤ Contributing

To improve Docker deployment:

1. Test on your setup
2. Report issues
3. Submit improvements
4. Share your docker-compose.override.yml examples

## ğŸ“ Support

- ğŸ“– Docs: See above links
- ğŸ› Issues: GitHub Issues
- ğŸ’¬ Questions: Create an issue

---

**Ready to deploy?** â†’ Start with [QUICKSTART.Docker.md](QUICKSTART.Docker.md)
